{
  "_comment": "PhenixCode Embedder RAG System Configuration Template v1.0.0",
  "_version": "1.0.0",
  "_docs": "https://github.com/nesall/embedder_cpp/wiki/configuration",
  
  "placeholder_descriptions": {
    "_comment": "Placeholders will be replaced during setup wizard",
    "_PL_EMB_API_URL_": "Embedding API base URL",
    "_PL_EMB_API_KEY_": "Embedding API access key",
    "_PL_EMB_MODEL_NAME_": "Embedding model name",
    "_PL_CMPL_API_URL_": "Completion API base URL",
    "_PL_CMPL_API_KEY_": "Completion API access key",
    "_PL_CMPL_MODEL_NAME_": "Completion model name"
  },
  "tokenizer": {
    "config_path": "./bge_tokenizer.json"
  },
  "embedding": {
    "apis": [
      {
        "id": "custom",
        "name": "Custom",
        "api_url": "_PL_EMB_API_URL_",
        "api_key": "_PL_EMB_API_KEY_",
        "model": "_PL_EMB_MODEL_NAME_",
        "document_format": "{}",
        "query_format": "{}"
      },
      {
        "api_key": "",
        "api_url": "http://127.0.0.1:8583/embedding",
        "id": "local",
        "model": "bge-base-v1.5",
        "name": "llamacpp-server",
        "document_format": "{}",
        "query_format": "Represent this sentence for searching relevant passages: {}"
      }
    ],
    "current_api": "local",
    "batch_size": 4,
    "timeout_ms": 30000,
    "retry_attempts": 3,
    "top_k": 5,
    "prepend_label_format": "[Source: {}]\n"
  },
  "generation": {
    "apis": [
      {
        "id": "custom",
        "name": "Custom",
        "api_url": "_PL_CMPL_API_URL_",
        "api_key": "_PL_CMPL_API_KEY_",
        "model": "_PL_CMPL_MODEL_NAME_",
        "pricing_tpm": {
          "input": 0.00,
          "cached_input": 0.00,
          "output": 0.00
        },
        "context_length": 100000
      },
      {
        "api_key": "",
        "api_url": "http://127.0.0.1:8587/v1/chat/completions",
        "enabled": true,
        "id": "local-fim-gemma",
        "model": "codegemma-2b-fim",
        "name": "Local",
        "pricing_tpm": {
          "input": 0,
          "output": 0
        },
        "fim": {
          "api_url": "http://127.0.0.1:8587/v1/completions",
          "format": "<|fim_prefix|>{}<|fim_suffix|>{}<|fim_middle|>",
          "file_divider_token": "<|file_separator|>",
          "stop_tokens": ["return", "<|fim_prefix|>", "<|fim_middle|>"]
        }
      },
      {
        "api_key": "${MISTRAL_API_KEY}",
        "api_url": "https://api.mistral.ai/v1/chat/completions",
        "id": "mistral-devstral-small",
        "model": "devstral-small-latest",
        "name": "Mistral",
        "pricing_tpm": {
          "input": 0.1,
          "output": 0.3
        },
        "context_length": 128000
      },
      {
        "api_key": "${CODESTRAL_API_KEY}",
        "api_url": "https://codestral.mistral.ai/v1/chat/completions",
        "context_length": 256000,
        "enabled": true,
        "id": "mistral-codestral",
        "model": "codestral-latest",
        "name": "Mistral",
        "fim": {
          "api_url": "https://codestral.mistral.ai/v1/fim/completions",
          "prefix_name": "prompt",
          "suffix_name": "suffix", 
          "stop_tokens": []
        },
        "pricing_tpm": {
          "input": 0.3,
          "output": 0.9
        }
      },
      {
        "api_key": "${GEMINI_API_KEY}",
        "api_url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
        "id": "gemini-2.5-flash",
        "model": "gemini-2.5-flash",
        "name": "Gemini",
        "pricing_tpm": {
          "input": 0.1,
          "output": 0.4
        },
        "context_length": 1000000
      },      
      {
        "api_key": "${DEEPSEEK_API_KEY}",
        "api_url": "https://api.deepseek.com/chat/completions",
        "id": "deepseek",
        "model": "deepseek-chat",
        "name": "DeepSeek",
        "pricing_tpm": {
          "cached_input": 0.028,
          "input": 0.28,
          "output": 0.42
        },
        "context_length": 128000
      },      
      {
        "api_key": "${XAI_API_KEY}",
        "api_url": "https://api.x.ai/v1/chat/completions",
        "id": "xai",
        "model": "grok-4-1-fast-non-reasoning",
        "name": "X AI",
        "pricing_tpm": {
          "cached_input": 0.05,
          "input": 0.2,
          "output": 0.5
        },
        "context_length": 2000000
      },
      {
        "api_key": "${OPENAI_API_KEY}",
        "api_url": "https://api.openai.com/v1/chat/completions",
        "id": "openai-4o-mini",
        "model": "gpt-4o-mini",
        "name": "OpenAI",
        "max_tokens_name": "max_completion_tokens",
        "pricing_tpm": {
          "cached_input": 0.075,
          "input": 0.15,
          "output": 0.6
        },
        "context_length": 128000
      },
      {
        "api_key": "${MINIMAX_API_KEY}",
        "api_url": "https://api.x.ai/v1/chat/completions",
        "context_length": 204000,
        "enabled": true,
        "id": "minimax-m2.1",
        "model": "MiniMax-M2.1",
        "name": "Minimax",
        "pricing_tpm": {
          "cached_input": 0.03,
          "input": 0.3,
          "output": 1.2
        }
      },      
    ],
    "current_api": "mistral-devstral",
    "timeout_ms": 120000,
    "max_chunks": 7,
    "max_full_sources": 2,
    "max_related_per_source": 3,
    "max_context_tokens": 64000,
    "default_temperature": 0.1,
    "default_max_tokens": 2048,
    "default_max_tokens_name": "max_tokens",
    "prepend_label_format": "[Source: {}]\n",
    "excerpt": {
      "enabled": true,
      "min_chunks": 3,
      "max_chunks": 15,
      "threshold_ratio": 0.75
    }
  },
  "database": {
    "sqlite_path": "./db_metadata.db",
    "index_path": "./db_embeddings.index",
    "vector_dim": 768,
    "max_elements": 100000,
    "distance_metric": "cosine",
    "_comment": "For distance_metric use either cosine (default) or l2"
  },
  "chunking": {
    "semantic": true,
    "nof_min_tokens": 50,
    "nof_max_tokens": 450,
    "overlap_percentage": 0.2
  },
  "source": {
    "_comment_project_id": "Leave empty to auto-generate from config path, or set a custom stable project_id",
    "project_id": "",
    "project_title": "Default Project Title",
    "project_description": "",
    "paths":[
      {
        "exclude": [],
        "extensions": [],
        "path": "./",
        "recursive": true,
        "type": "directory"
      }
    ],  
    "default_extensions": [ ".c", ".cpp", ".h", ".hpp", ".py", ".js", ".ts", ".java", ".rs", ".cs", ".xaml", ".php", ".jsp", ".html", ".css", ".md" ],
    "global_exclude": [
      "*/node_modules/*", "*.min.js", "*.log", "*/build/*",
      "*/.git/*", ".gitignore", "*/CVS/*",
      "*/debug/*", "*/release/*", "*/lib/*", "*/docker/*",
      "*/fonts/*", "*/images/*", "*/test/*","*/tests/*",
      "*/example/*", "*/examples/*", "*/obj/*", "*/build_dbg/*", "*/build_rel/*",
      "*/dist/*", "*/test/*", "*/3rdparty/*", "*/cmake-build/*"
    ],
    "encoding": "utf-8",
    "max_file_size_mb": 10
  },
  "logging": {
    "log_to_console": true,
    "log_to_file": true,
    "logging_file": "embedder.log",
    "diagnostics_file": "embedder_d.log"
  }
}